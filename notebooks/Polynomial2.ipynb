{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Astropy\n",
    "import astropy\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "\n",
    "# dlnpyutils\n",
    "# from dlnpyutils.utils import bspline, mad\n",
    "from dlnpyutils import utils as dln\n",
    "\n",
    "### Itertools\n",
    "import itertools as it\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams.update({'font.size': 25})\n",
    "\n",
    "#Numpy/Scipy\n",
    "import numpy as np\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline as IUS\n",
    "from scipy.interpolate import interp1d, interp2d\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import binned_statistic, binned_statistic_2d\n",
    "\n",
    "### fitting\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# tqdm\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Age of Universe\n",
    "universe = 13.787 #+/- 0.020 Gyr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARSEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "massive = fits.getdata('/Users/joshuapovick/Desktop/Research/parsec/parsec36_DR2_EDR3.fits')\n",
    "massive = Table(massive[np.where(massive['label']==3.0)])\n",
    "massive = massive[np.argsort(massive['logAge'])]\n",
    "massive = massive['MH','Mass','logAge','logTe','logg','G_BPEDR3mag','GEDR3mag','G_RPEDR3mag',\n",
    "                  'Jmag','Hmag','Ksmag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### PCA\n",
    "# from sklearn.decomposition import PCA, KernelPCA\n",
    "\n",
    "# ### Setup \n",
    "# data = np.array([massive['G_BPEDR3mag'],massive['GEDR3mag'],massive['G_RPEDR3mag'],massive['Jmag'],massive['Hmag'],massive['Ksmag']]).T\n",
    "\n",
    "# ### Determine Number of factors\n",
    "# pca = PCA(n_components=6).fit(data)#_rescaled)\n",
    "# plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# y = np.cumsum(pca.explained_variance_ratio_)\n",
    "# xi = np.arange(1, len(pca.explained_variance_ratio_)+1, step=1)\n",
    "\n",
    "# plt.ylim(0.0,1.1)\n",
    "# plt.plot(xi, y, marker='o', linestyle='--', color='b')\n",
    "\n",
    "# plt.xlabel('Number of Components')\n",
    "# plt.xticks(np.arange(0, 7, step=1)) #change from 0-based array index to 1-based human-readable label\n",
    "# plt.ylabel('Cumulative variance (%)')\n",
    "# plt.title('The number of components needed to explain variance')\n",
    "\n",
    "# plt.axhline(y=0.99, color='r', linestyle='-')\n",
    "# plt.text(0.5, 0.85, '99% cut-off threshold', color = 'red', fontsize=16)\n",
    "\n",
    "# ax.grid(axis='x')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_phot = PCA(n_components=1).fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=[10,10])\n",
    "# plt.scatter(massive['GEDR3mag']-new_phot,massive['GEDR3mag'],c=massive['MH'],cmap='nipy_spectral')\n",
    "# plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=[10,10])\n",
    "# plt.scatter(new_phot[:,1]-new_phot[:,0],new_phot[:,0],c=massive['MH'],cmap='nipy_spectral')\n",
    "# plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_phot[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['logAge'] = massive['logAge']\n",
    "\n",
    "### Linear\n",
    "df['MH'] = massive['MH']\n",
    "df['logTe'] = massive['logTe']\n",
    "df['logg'] = massive['logg']\n",
    "df['GEDR3mag'] = massive['GEDR3mag']\n",
    "\n",
    "# ### Linear Interactions\n",
    "# df['MH_logTe'] = np.multiply(df['MH'],df['logTe'])\n",
    "# df['MH_logg'] = np.multiply(df['MH'],df['logg'])\n",
    "# df['MH_GEDR3mag'] = np.multiply(df['MH'],df['GEDR3mag'])\n",
    "# df['logTe_logg'] = np.multiply(df['logTe'],df['logg'])\n",
    "# df['logTe_GEDR3mag'] = np.multiply(df['logTe'],df['GEDR3mag'])\n",
    "# df['logg_GEDR3mag'] = np.multiply(df['logg'],df['GEDR3mag'])\n",
    "\n",
    "### Square\n",
    "df['MHsq'] = df['MH']**2\n",
    "df['logTesq'] = df['logTe']**2\n",
    "df['loggsq'] = df['logg']**2\n",
    "df['GEDR3magsq'] = df['GEDR3mag']**2\n",
    "\n",
    "### Cubic\n",
    "df['MHcu'] = df['MH']**3\n",
    "df['logTecu'] = df['logTe']**3\n",
    "df['loggcu'] = df['logg']**3\n",
    "df['GEDR3magcu'] = df['GEDR3mag']**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "def forward_selected(data, response):\n",
    "    \"\"\"Linear model designed by forward selection.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas DataFrame with all possible predictors and response\n",
    "\n",
    "    response: string, name of response column in data\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    model: an \"optimal\" fitted statsmodels linear model\n",
    "           with an intercept\n",
    "           selected by forward selection\n",
    "           evaluated by adjusted R-squared\n",
    "    \"\"\"\n",
    "    remaining = set(data.columns)\n",
    "    remaining.remove(response)\n",
    "    selected = []\n",
    "    current_score, best_new_score = 0.0, 0.0\n",
    "    while remaining and current_score == best_new_score:\n",
    "        scores_with_candidates = []\n",
    "        for candidate in remaining:\n",
    "            formula = \"{} ~ {} + 1\".format(response,\n",
    "                                           ' + '.join(selected + [candidate]))\n",
    "            score = smf.ols(formula, data).fit().rsquared_adj\n",
    "            scores_with_candidates.append((score, candidate))\n",
    "        scores_with_candidates.sort()\n",
    "        best_new_score, best_candidate = scores_with_candidates.pop()\n",
    "        if current_score < best_new_score:\n",
    "            remaining.remove(best_candidate)\n",
    "            selected.append(best_candidate)\n",
    "            current_score = best_new_score\n",
    "    formula = \"{} ~ {} + 1\".format(response,\n",
    "                                   ' + '.join(selected))\n",
    "    model = smf.ols(formula, data).fit()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = forward_selected(df, 'logAge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logAge ~ GEDR3magcu + logg + GEDR3mag + logTe + logTesq + logTecu + MH + loggcu + MHsq + GEDR3magsq + MHcu + loggsq + 1'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Split Training\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import pandas as pd\n",
    "\n",
    "# df = massive.to_pandas()\n",
    "# df.drop(columns=['Mass','logAge'])\n",
    "\n",
    "# ptrain, ptest, atrain, atest = train_test_split(massive['MH','logTe','logg','G_BPEDR3mag','GEDR3mag','G_RPEDR3mag','Jmag','Hmag','Ksmag'],\n",
    "#                                                 massive['logAge'],test_size=0.20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "\n",
    "# cov_mat = np.round(np.cov(np.array([massive['MH'],massive['logTe'],massive['logg'],massive['G_BPEDR3mag'],\n",
    "#                                     massive['GEDR3mag'],massive['G_RPEDR3mag']])))\n",
    "\n",
    "# plt.figure\n",
    "# plt.imshow(cov_mat)\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "# eigen_values, eigen_vectors = np.linalg.eig(cov_mat)\n",
    "# print(\"Eigenvector: \\n\",eigen_vectors,\"\\n\")\n",
    "# print(\"Eigenvalues: \\n\", eigen_values, \"\\n\")\n",
    "\n",
    "# variance_explained = []\n",
    "# for i in eigen_values:\n",
    "#      variance_explained.append((i/sum(eigen_values))*100)\n",
    "        \n",
    "# print(variance_explained)\n",
    "\n",
    "# cumulative_variance_explained = np.cumsum(variance_explained)\n",
    "# print(cumulative_variance_explained)\n",
    "\n",
    "# plt.figure(figsize=[12,7])\n",
    "# sns.lineplot(x = [1,2,3,4,5,6], y=cumulative_variance_explained)\n",
    "# plt.xlabel(\"Number of components\")\n",
    "# plt.ylabel(\"Cumulative explained variance\")\n",
    "# plt.title(\"Explained variance vs Number of components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-547d60b1a637>:47: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  models = np.array(models)\n",
      "<ipython-input-21-547d60b1a637>:48: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  models_str = np.array(models_str)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc46a398f6a408b89ee1c2472362513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Done?:   0%|          | 0/4095 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Find all models\n",
    "\n",
    "### PCA\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "\n",
    "data = np.array([massive['logTe'],massive['GEDR3mag'],massive['MH'],massive['logg']]).T\n",
    "\n",
    "#transform data to new basis\n",
    "new_data = PCA(n_components=3).fit(data).transform(data)\n",
    "\n",
    "#create new variables\n",
    "\n",
    "# linear terms\n",
    "x1 = new_data[:,0]\n",
    "x2 = new_data[:,1]\n",
    "x3 = new_data[:,2]\n",
    "\n",
    "# linear int\n",
    "x12 = np.multiply(x1,x2)\n",
    "x13 = np.multiply(x1,x3)\n",
    "x23 = np.multiply(x2,x3)\n",
    "\n",
    "# squares\n",
    "x1sq = x1**2\n",
    "x2sq = x2**2\n",
    "x3sq = x3**2\n",
    "\n",
    "# cubes\n",
    "x1cu = x1**3\n",
    "x2cu = x2**3\n",
    "x3cu = x3**3\n",
    "\n",
    "\n",
    "#find all possible models\n",
    "models = []\n",
    "models_str = []\n",
    "\n",
    "all_var_str = ['x1','x2','x3','x12','x13','x23','x1sq','x2sq','x3sq','x1cu','x2cu','x3cu']\n",
    "all_var = [x1,x2,x3,x12,x13,x23,x1sq,x2sq,x3sq,x1cu,x2cu,x3cu]\n",
    "\n",
    "for i in range(1,len(all_var)+1):\n",
    "    for subset in it.combinations(all_var,i):\n",
    "        models.append(subset)\n",
    "    for subset_str in it.combinations(all_var_str,i):\n",
    "        models_str.append(np.array(subset_str))\n",
    "        \n",
    "models = np.array(models)\n",
    "models_str = np.array(models_str)\n",
    "\n",
    "### Fit All Models\n",
    "\n",
    "import statsmodels.api as sm \n",
    "\n",
    "all_params = []\n",
    "summaries = []\n",
    "max_resid = []\n",
    "mads = []\n",
    "predict = []\n",
    "ll = []\n",
    "for i in tqdm(range(len(models)),desc='Done?'):\n",
    "    pmodl = np.array(models[i]).T\n",
    "    pmodl = sm.add_constant(pmodl)\n",
    "    model = sm.OLS(massive['logAge'],pmodl).fit()\n",
    "    summaries.append(model.summary())\n",
    "    predictions = model.predict(pmodl)\n",
    "    predict.append(predictions)\n",
    "    residual = predictions - massive['logAge']\n",
    "    all_params.append(np.asarray(model.params))\n",
    "    max_resid.append(np.max(np.absolute(residual)))\n",
    "    mads.append(dln.mad(residual))\n",
    "    ll.append(model.llf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261156"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e5bf1331de42628a6016338284804e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Done?:   0%|          | 0/261156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-bf1f617ee2bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Done?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mpmodl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mpmodl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpmodl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmassive\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'logAge'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpmodl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpmodl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/statsmodels/tools/tools.py\u001b[0m in \u001b[0;36madd_constant\u001b[0;34m(data, prepend, has_constant)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprepend\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mcolumn_stack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mcolumn_stack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ### Fit All Models\n",
    "\n",
    "# import statsmodels.api as sm \n",
    "\n",
    "# dat = np.array([]).T\n",
    "\n",
    "# all_params = []\n",
    "# max_resid = []\n",
    "# mads = []\n",
    "# ll = []\n",
    "# for i in tqdm(range(len(models)),desc='Done?'):\n",
    "#     pmodl = np.array(models[i]).T\n",
    "#     pmodl = sm.add_constant(pmodl)\n",
    "#     model = sm.OLS(massive['logAge'],pmodl).fit()\n",
    "#     predictions = model.predict(pmodl)\n",
    "#     residual = predictions - massive['logAge']\n",
    "#     all_params.append(np.asarray(model.params))\n",
    "#     max_resid.append(np.max(np.absolute(residual)))\n",
    "#     mads.append(dln.mad(residual))\n",
    "#     ll.append(model.llf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x1', 'x2', 'x3', 'x0sq', 'x1sq', 'x3sq', 'x1cu', 'x2cu', 'x3cu'],\n",
       "      dtype='<U4')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_str[np.array(mads).argmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.961</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.961</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>5.968e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 06 Aug 2022</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:18:08</td>     <th>  Log-Likelihood:    </th> <td>3.8617e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>2916369</td>     <th>  AIC:               </th> <td>-7.723e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>2916356</td>     <th>  BIC:               </th> <td>-7.723e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    12</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>-9612.4450</td> <td>    4.827</td> <td>-1991.368</td> <td> 0.000</td> <td>-9621.906</td> <td>-9602.984</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.1682</td> <td>    0.000</td> <td> -411.713</td> <td> 0.000</td> <td>   -0.169</td> <td>   -0.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td> 7696.1086</td> <td>    3.968</td> <td> 1939.438</td> <td> 0.000</td> <td> 7688.331</td> <td> 7703.886</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -2.3302</td> <td>    0.001</td> <td>-2056.261</td> <td> 0.000</td> <td>   -2.332</td> <td>   -2.328</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    1.1072</td> <td>    0.000</td> <td> 5470.296</td> <td> 0.000</td> <td>    1.107</td> <td>    1.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.0375</td> <td>    0.000</td> <td> -134.739</td> <td> 0.000</td> <td>   -0.038</td> <td>   -0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>-2051.4036</td> <td>    1.088</td> <td>-1886.215</td> <td> 0.000</td> <td>-2053.535</td> <td>-2049.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.0052</td> <td>    0.000</td> <td>   11.623</td> <td> 0.000</td> <td>    0.004</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0045</td> <td>  4.2e-05</td> <td>  107.325</td> <td> 0.000</td> <td>    0.004</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.0108</td> <td>    0.000</td> <td>  -96.055</td> <td> 0.000</td> <td>   -0.011</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>  182.3288</td> <td>    0.099</td> <td> 1834.629</td> <td> 0.000</td> <td>  182.134</td> <td>  182.524</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.0066</td> <td> 8.67e-05</td> <td>  -76.243</td> <td> 0.000</td> <td>   -0.007</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -0.0011</td> <td> 8.89e-06</td> <td> -119.233</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1051382.186</td> <th>  Durbin-Watson:     </th>   <td>   0.446</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>    <th>  Jarque-Bera (JB):  </th> <td>520043390.777</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td> 0.200</td>    <th>  Prob(JB):          </th>   <td>    0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td>68.418</td>    <th>  Cond. No.          </th>   <td>8.89e+06</td>   \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 8.89e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.961\n",
       "Model:                            OLS   Adj. R-squared:                  0.961\n",
       "Method:                 Least Squares   F-statistic:                 5.968e+06\n",
       "Date:                Sat, 06 Aug 2022   Prob (F-statistic):               0.00\n",
       "Time:                        12:18:08   Log-Likelihood:             3.8617e+06\n",
       "No. Observations:             2916369   AIC:                        -7.723e+06\n",
       "Df Residuals:                 2916356   BIC:                        -7.723e+06\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const      -9612.4450      4.827  -1991.368      0.000   -9621.906   -9602.984\n",
       "x1            -0.1682      0.000   -411.713      0.000      -0.169      -0.167\n",
       "x2          7696.1086      3.968   1939.438      0.000    7688.331    7703.886\n",
       "x3            -2.3302      0.001  -2056.261      0.000      -2.332      -2.328\n",
       "x4             1.1072      0.000   5470.296      0.000       1.107       1.108\n",
       "x5            -0.0375      0.000   -134.739      0.000      -0.038      -0.037\n",
       "x6         -2051.4036      1.088  -1886.215      0.000   -2053.535   -2049.272\n",
       "x7             0.0052      0.000     11.623      0.000       0.004       0.006\n",
       "x8             0.0045    4.2e-05    107.325      0.000       0.004       0.005\n",
       "x9            -0.0108      0.000    -96.055      0.000      -0.011      -0.011\n",
       "x10          182.3288      0.099   1834.629      0.000     182.134     182.524\n",
       "x11           -0.0066   8.67e-05    -76.243      0.000      -0.007      -0.006\n",
       "x12           -0.0011   8.89e-06   -119.233      0.000      -0.001      -0.001\n",
       "==============================================================================\n",
       "Omnibus:                  1051382.186   Durbin-Watson:                   0.446\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):        520043390.777\n",
       "Skew:                           0.200   Prob(JB):                         0.00\n",
       "Kurtosis:                      68.418   Cond. No.                     8.89e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 8.89e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmodl = np.array([x0,x1,x2,x3,x0sq,x1sq,x2sq,x3sq,x0cu,x1cu,x2cu,x3cu]).T\n",
    "pmodl = sm.add_constant(pmodl)\n",
    "model = sm.OLS(massive['logAge'],pmodl).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(np.array([x1,x2,x3,x0sq,x1sq,x3sq,x1cu,x2cu,x3cu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2eq(model_str,model_params):\n",
    "    '''\n",
    "    Create polynomial model using string and parameters included. Assuming the existence of a constant term\n",
    "    and the following conventions\n",
    "    \n",
    "    xN: linear term\n",
    "    xNsq: square term\n",
    "    xNcu: cubic term\n",
    "    \n",
    "    Input:\n",
    "    -----\n",
    "        model_str:    array of length N\n",
    "                      strings of model variables\n",
    "                      \n",
    "        model_params: array of length N+1\n",
    "                      model parameters with model_params[0] as the constant term and every other as the \n",
    "                      coresponding value for each element of model_str\n",
    "    '''\n",
    "    \n",
    "    var =\n",
    "    deg = 999999.0*np.\n",
    "    \n",
    "    for i in range(len(model_str)):\n",
    "        if model_str[:-2] == 'cu':\n",
    "            deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'x1cu'[-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01,02,03\n",
    "12,13\n",
    "23"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
